{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb037952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "from os.path import isfile,expanduser\n",
    "import numpy as np\n",
    "import h5py\n",
    "import illustris_python as il\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy as sp\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16319412",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepaths = {'TNG100': ['/virgotng/universe/IllustrisTNG/TNG100-1/postprocessing/XrayEmission/',99],\n",
    "             'SIMBA': ['/virgotng/universe/Simba/L100n1024FP/postprocessing/XrayEmission/',151],\n",
    "             'EAGLE': ['/virgotng/universe/Eagle/Eagle100-1/postprocessing/XrayEmission/',28]  }\n",
    "\n",
    "\n",
    "basepaths2 = {'TNG100': ['/virgotng/universe/IllustrisTNG/TNG100-1/output',99],\n",
    "              'SIMBA': ['/virgotng/universe/Simba/L100n1024FP/output',151],\n",
    "              'EAGLE': ['/virgotng/universe/Eagle/Eagle100-1/output',28]  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ea0d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(u, v, box_length):\n",
    "    \"\"\"\n",
    "    returns the position vector u-v in a periodic Cartesian box\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    u : N x 3 position array\n",
    "    v : N x 3 OR 1 x 3 position array\n",
    "    box_length : float in same units as [u], [v]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result: N x M position vector (array)\n",
    "    \"\"\"\n",
    "\n",
    "    result = u - v\n",
    "    result[result > box_length / 2.0] -= box_length\n",
    "    result[result < -box_length / 2.0] += box_length\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def mass_mask(basepath, snapshot, mi = 10**12.5 , ma = 10**14.3):\n",
    "    '''\n",
    "    takes the basepath and snapshot number as inputs for a sim\n",
    "    and applies a mask in Group_M_Crit200\n",
    "    returns the masses and the ids of these groups\n",
    "    '''\n",
    "    \n",
    "    # Loading header\n",
    "    header = il.groupcat.loadHeader(basepath, snapshot)\n",
    "    h = header['HubbleParam']\n",
    "    a = header['Time']\n",
    "\n",
    "    # Loading halo data\n",
    "    GroupMass = il.groupcat.loadHalos(basepath, snapshot, fields=['Group_M_Crit200']) * 10**10 / h  # Msun\n",
    "\n",
    "    # Apply mass cut\n",
    "    haloIDs = np.where((GroupMass > mi) & (GroupMass < ma))[0]\n",
    "    GroupMass = GroupMass[haloIDs]\n",
    "        \n",
    "    return GroupMass, haloIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b34477e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumPart(header):\n",
    "    \"\"\" Calculate number of particles of all types given a snapshot header. \"\"\"\n",
    "    if 'NumPart_Total_HighWord' not in header:\n",
    "        return header['NumPart_Total'] # new uint64 convention\n",
    "\n",
    "    nTypes = 6\n",
    "\n",
    "    nPart = np.zeros(nTypes, dtype=np.int64)\n",
    "    for j in range(nTypes):\n",
    "        nPart[j] = header['NumPart_Total'][j] | (header['NumPart_Total_HighWord'][j] << 32)\n",
    "\n",
    "    return nPart\n",
    "\n",
    "\n",
    "\n",
    "def partTypeNum(partType):\n",
    "    \"\"\" Mapping between common names and numeric particle types. \"\"\"\n",
    "    if str(partType).isdigit():\n",
    "        return int(partType)\n",
    "        \n",
    "    if str(partType).lower() in ['gas','cells']:\n",
    "        return 0\n",
    "    if str(partType).lower() in ['dm','darkmatter']:\n",
    "        return 1\n",
    "    if str(partType).lower() in ['dmlowres']:\n",
    "        return 2 # only zoom simulations, not present in full periodic boxes\n",
    "    if str(partType).lower() in ['tracer','tracers','tracermc','trmc']:\n",
    "        return 3\n",
    "    if str(partType).lower() in ['star','stars','stellar']:\n",
    "        return 4 # only those with GFM_StellarFormationTime>0\n",
    "    if str(partType).lower() in ['wind']:\n",
    "        return 4 # only those with GFM_StellarFormationTime<0\n",
    "    if str(partType).lower() in ['bh','bhs','blackhole','blackholes']:\n",
    "        return 5\n",
    "    \n",
    "    raise Exception(\"Unknown particle type name.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "def gcPath(basePath, snapNum, chunkNum=0):\n",
    "    \"\"\" Return absolute path to a group catalog HDF5 file (modify as needed). \"\"\"\n",
    "    gcPath = basePath + '../../output/groups_%03d/' % snapNum\n",
    "    filePath1 = gcPath + 'groups_%03d.%d.hdf5' % (snapNum, chunkNum)\n",
    "    filePath2 = gcPath + 'fof_subhalo_tab_%03d.%d.hdf5' % (snapNum, chunkNum)\n",
    "\n",
    "    if isfile(expanduser(filePath1)):\n",
    "        return filePath1\n",
    "    return filePath2\n",
    "\n",
    "\n",
    "\n",
    "def offsetPath(basePath, snapNum):\n",
    "    \"\"\" Return absolute path to a separate offset file (modify as needed). \"\"\"\n",
    "    offsetPath = basePath + '/../offsets/offsets_%03d.hdf5' % snapNum\n",
    "\n",
    "    return offsetPath\n",
    "\n",
    "\n",
    "\n",
    "def getSnapOffsets(basePath, snapNum, id, type):\n",
    "    \"\"\" Compute offsets within snapshot for a particular group/subgroup. \"\"\"\n",
    "    r = {}\n",
    "\n",
    "    # old or new format\n",
    "    if 'fof_subhalo' in gcPath(basePath, snapNum):\n",
    "        # use separate 'offsets_nnn.hdf5' files\n",
    "        with h5py.File(offsetPath(basePath, snapNum), 'r') as f:\n",
    "            groupFileOffsets = f['FileOffsets/'+type][()]\n",
    "            r['snapOffsets'] = np.transpose(f['FileOffsets/SnapByType'][()])  # consistency\n",
    "    else:\n",
    "        # load groupcat chunk offsets from header of first file\n",
    "        with h5py.File(gcPath(basePath, snapNum), 'r') as f:\n",
    "            groupFileOffsets = f['Header'].attrs['FileOffsets_'+type]\n",
    "            r['snapOffsets'] = f['Header'].attrs['FileOffsets_Snap']\n",
    "\n",
    "    # calculate target groups file chunk which contains this id\n",
    "    groupFileOffsets = int(id) - groupFileOffsets\n",
    "    fileNum = np.max(np.where(groupFileOffsets >= 0))\n",
    "    groupOffset = groupFileOffsets[fileNum]\n",
    "\n",
    "    # load the length (by type) of this group/subgroup from the group catalog\n",
    "    with h5py.File(gcPath(basePath, snapNum, fileNum), 'r') as f:\n",
    "        r['lenType'] = f[type][type+'LenType'][groupOffset, :]\n",
    "\n",
    "    # old or new format: load the offset (by type) of this group/subgroup within the snapshot\n",
    "    if 'fof_subhalo' in gcPath(basePath, snapNum):\n",
    "        with h5py.File(offsetPath(basePath, snapNum), 'r') as f:\n",
    "            r['offsetType'] = f[type+'/SnapByType'][id, :]\n",
    "\n",
    "            # add TNG-Cluster specific offsets if present\n",
    "            if 'OriginalZooms' in f:\n",
    "                for key in f['OriginalZooms']:\n",
    "                    r[key] = f['OriginalZooms'][key][()] \n",
    "    else:\n",
    "        with h5py.File(gcPath(basePath, snapNum, fileNum), 'r') as f:\n",
    "            r['offsetType'] = f['Offsets'][type+'_SnapByType'][groupOffset, :]\n",
    "\n",
    "    return r\n",
    "\n",
    "\n",
    "\n",
    "def loadSubset(basePath, snapNum, partType, fields=None, subset=None, mdi=None, sq=True, float32=False):\n",
    "    \"\"\" Load a subset of fields for all particles/cells of a given partType.\n",
    "        If offset and length specified, load only that subset of the partType.\n",
    "        If mdi is specified, must be a list of integers of the same length as fields,\n",
    "        giving for each field the multi-dimensional index (on the second dimension) to load.\n",
    "          For example, fields=['Coordinates', 'Masses'] and mdi=[1, None] returns a 1D array\n",
    "          of y-Coordinates only, together with Masses.\n",
    "        If sq is True, return a numpy array instead of a dict if len(fields)==1.\n",
    "        If float32 is True, load any float64 datatype arrays directly as float32 (save memory). \"\"\"\n",
    "    result = {}\n",
    "\n",
    "    ptNum = partTypeNum(partType)\n",
    "    gName = \"PartType\" + str(ptNum)\n",
    "\n",
    "    # make sure fields is not a single element\n",
    "    if isinstance(fields, six.string_types):\n",
    "        fields = [fields]\n",
    "\n",
    "    # load header from first chunk\n",
    "    with h5py.File(il.snapshot.snapPath(basePath, snapNum), 'r') as f:\n",
    "\n",
    "        header = dict(f['Header'].attrs.items())\n",
    "        nPart = il.snapshot.getNumPart(header)\n",
    "\n",
    "        # decide global read size, starting file chunk, and starting file chunk offset\n",
    "        if subset:\n",
    "            offsetsThisType = subset['offsetType'][ptNum] - subset['snapOffsets'][ptNum, :]\n",
    "\n",
    "            fileNum = np.max(np.where(offsetsThisType >= 0))\n",
    "            fileOff = offsetsThisType[fileNum]\n",
    "            numToRead = subset['lenType'][ptNum]\n",
    "        else:\n",
    "            fileNum = 0\n",
    "            fileOff = 0\n",
    "            numToRead = nPart[ptNum]\n",
    "\n",
    "        result['count'] = numToRead\n",
    "\n",
    "        if not numToRead:\n",
    "            # print('warning: no particles of requested type, empty return.')\n",
    "            return result\n",
    "\n",
    "        # find a chunk with this particle type\n",
    "        i = 1\n",
    "        while gName not in f:\n",
    "            f = h5py.File(il.snapshot.snapPath(basePath, snapNum, i), 'r')\n",
    "            i += 1\n",
    "\n",
    "        # if fields not specified, load everything\n",
    "        if not fields:\n",
    "            fields = list(f[gName].keys())\n",
    "\n",
    "        for i, field in enumerate(fields):\n",
    "            # verify existence\n",
    "            if field not in f[gName].keys():\n",
    "                raise Exception(\"Particle type [\"+str(ptNum)+\"] does not have field [\"+field+\"]\")\n",
    "\n",
    "            # replace local length with global\n",
    "            shape = list(f[gName][field].shape)\n",
    "            shape[0] = numToRead\n",
    "\n",
    "            # multi-dimensional index slice load\n",
    "            if mdi is not None and mdi[i] is not None:\n",
    "                if len(shape) != 2:\n",
    "                    raise Exception(\"Read error: mdi requested on non-2D field [\"+field+\"]\")\n",
    "                shape = [shape[0]]\n",
    "\n",
    "            # allocate within return dict\n",
    "            dtype = f[gName][field].dtype\n",
    "            if dtype == np.float64 and float32: dtype = np.float32\n",
    "            result[field] = np.zeros(shape, dtype=dtype)\n",
    "\n",
    "    # loop over chunks\n",
    "    wOffset = 0\n",
    "    origNumToRead = numToRead\n",
    "\n",
    "    while numToRead:\n",
    "        f = h5py.File(il.snapshot.snapPath(basePath, snapNum, fileNum), 'r')\n",
    "\n",
    "        # no particles of requested type in this file chunk?\n",
    "        if gName not in f:\n",
    "            f.close()\n",
    "            fileNum += 1\n",
    "            fileOff  = 0\n",
    "            continue\n",
    "\n",
    "        # set local read length for this file chunk, truncate to be within the local size\n",
    "        numTypeLocal = f['Header'].attrs['NumPart_ThisFile'][ptNum]\n",
    "\n",
    "        numToReadLocal = numToRead\n",
    "\n",
    "        if fileOff + numToReadLocal > numTypeLocal:\n",
    "            numToReadLocal = numTypeLocal - fileOff\n",
    "\n",
    "        #print('['+str(fileNum).rjust(3)+'] off='+str(fileOff)+' read ['+str(numToReadLocal)+\\\n",
    "        #      '] of ['+str(numTypeLocal)+'] remaining = '+str(numToRead-numToReadLocal))\n",
    "\n",
    "        # loop over each requested field for this particle type\n",
    "        for i, field in enumerate(fields):\n",
    "            # read data local to the current file\n",
    "            if mdi is None or mdi[i] is None:\n",
    "                result[field][wOffset:wOffset+numToReadLocal] = f[gName][field][fileOff:fileOff+numToReadLocal]\n",
    "            else:\n",
    "                result[field][wOffset:wOffset+numToReadLocal] = f[gName][field][fileOff:fileOff+numToReadLocal, mdi[i]]\n",
    "\n",
    "        wOffset   += numToReadLocal\n",
    "        numToRead -= numToReadLocal\n",
    "        fileNum   += 1\n",
    "        fileOff    = 0  # start at beginning of all file chunks other than the first\n",
    "\n",
    "        f.close()\n",
    "\n",
    "    # verify we read the correct number\n",
    "    if origNumToRead != wOffset:\n",
    "        raise Exception(\"Read [\"+str(wOffset)+\"] particles, but was expecting [\"+str(origNumToRead)+\"]\")\n",
    "\n",
    "    # only a single field? then return the array instead of a single item dict\n",
    "    if sq and len(fields) == 1:\n",
    "        return result[fields[0]]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def loadHalo(basePath, snapNum, id, partType, fields=None):\n",
    "    \"\"\" Load all particles/cells of one type for a specific halo\n",
    "        (optionally restricted to a subset fields). \"\"\"\n",
    "    \n",
    "    # load halo length, compute offset, call loadSubset\n",
    "    subset = getSnapOffsets(basePath, snapNum, id, \"Group\")\n",
    "    \n",
    "    return loadSubset(basePath, snapNum, partType, fields, subset=subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df11bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xray_dict(sim_dict, sim_dict2):\n",
    "    '''\n",
    "    takes 2 dicts as input, sim_dict is { sim: [basepath,snapshot] } where basepath locates the Xray data\n",
    "    sim_dict2 is the same where basepath2 locates the output data (regular path)\n",
    "    returns a nested dict { sim: { haloID: { Xray_emission: values(for each gas cell) } } }\n",
    "    '''\n",
    "    \n",
    "    # initialise output dict\n",
    "    result = {}\n",
    "    \n",
    "    #loop for each sim\n",
    "    for sim2, basepath2 in sim_dict2.items():\n",
    "        \n",
    "        # get the ids of relevant mass halos\n",
    "        group_masses, haloIDs = mass_mask(basepath2[0], basepath2[1]) \n",
    "        \n",
    "        \n",
    "        #loop for each sim\n",
    "        for sim, basepath in sim_dict.items() :\n",
    "            if sim == sim2:\n",
    "                # start a new dict to save values of each sim\n",
    "                result[sim] = {}\n",
    "\n",
    "\n",
    "                #loop over the halo ids\n",
    "                for index, haloID in enumerate(haloIDs):\n",
    "\n",
    "                    halo_key = f'{haloID}'\n",
    "                    result[sim][halo_key] = {}\n",
    "\n",
    "                    Xray_em = loadHalo(basepath[0], basepath[1], haloID , 0, fields = ['Xray_Emission_05_2keV', 'Xray_Emission_03_2keV']) # erg*cm³/s\n",
    "\n",
    "                    result[sim][halo_key]['Xray_Emission_05_2keV'] = Xray_em['Xray_Emission_05_2keV'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['Xray_Emission_03_2keV'] = Xray_em['Xray_Emission_03_2keV'] # erg*cm³/s\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec097763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary \n",
    "#with open('../data/xray_em.pickle', 'wb') as file:\n",
    "#    pickle.dump(Xray_dict(basepaths, basepaths2), file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84296127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xray_lumdict(sim_dict, sim_dict2):\n",
    "    '''\n",
    "    takes 2 dicts as input, sim_dict is { sim: [basepath, snapshot] } where basepath locates the Xray data\n",
    "    sim_dict2 is the same where basepath2 locates the output data (regular path)\n",
    "    returns a nested dict { sim: { haloID: { field : value array } } }\n",
    "    '''\n",
    "    \n",
    "    # initialise output dict\n",
    "    result = {}\n",
    "    \n",
    "    #loop for each sim\n",
    "    for sim2, basepath2 in sim_dict2.items():\n",
    "        \n",
    "        # load header\n",
    "        header = il.groupcat.loadHeader(basepath2[0] , basepath2[1] )\n",
    "        h = header['HubbleParam']\n",
    "        a = header['Time']\n",
    "        BoxSize = header['BoxSize'] *a/h # pkpc\n",
    "        \n",
    "        # get the ids of relevant mass halos\n",
    "        group_masses, haloIDs = mass_mask(basepath2[0], basepath2[1]) # Msun\n",
    "        \n",
    "        # load all halos\n",
    "        Halos = il.groupcat.loadHalos(basepath2[0], basepath2[1], fields=['GroupPos', 'Group_R_Crit500', 'Group_R_Crit200'])\n",
    "        \n",
    "        #loop for each sim\n",
    "        for sim, basepath in sim_dict.items() :\n",
    "            if sim == sim2:\n",
    "                \n",
    "                # start a new dict to save values of each sim\n",
    "                result[sim] = {}\n",
    "                \n",
    "                #loop over the halo ids\n",
    "                for index, haloID in enumerate(haloIDs):\n",
    "\n",
    "                    halo_key = f'{haloID}'\n",
    "                    result[sim][halo_key] = {}\n",
    "                    \n",
    "                    # define halo data\n",
    "                    halo_pos = Halos['GroupPos'][haloID] *a/h  # pkpc\n",
    "                    R200c = Halos['Group_R_Crit200'][haloID] *a/h # pkpc\n",
    "                    R500c = Halos['Group_R_Crit500'][haloID] *a/h # pkpc\n",
    "                    \n",
    "                    # load gas data\n",
    "                    Gas = il.snapshot.loadHalo(basepath2[0] , basepath2[1] , haloID, 0)            \n",
    "                    Gas_mass = Gas['Masses'] *10**10/h  # Msun\n",
    "                    Gas_ea = Gas['ElectronAbundance'] # unitless\n",
    "                    Gas_density = Gas['Density'] *(10**10/h)/(a/h)**3 # Msun/pkpc³\n",
    "                    Gas_coords = Gas['Coordinates'] *a/h  # pkpc\n",
    "                    Centred_gas = shift(Gas_coords, halo_pos, BoxSize) # pkpc\n",
    "                    Gas_radius = np.linalg.norm(Centred_gas, axis =1) # pkpc\n",
    "                    \n",
    "                    # load xray data\n",
    "                    Xray_em = loadHalo(basepath[0], basepath[1], haloID, 0, fields = ['Xray_Emission_05_2keV', 'Xray_Emission_03_2keV']) # erg*cm³/s\n",
    "                    \n",
    "                    # calc Lx\n",
    "                    nh_conv = 6.768 *10**-32 # (Msun/pkpc**3 to g/cm**3)\n",
    "                    Xray_05 = Xray_em['Xray_Emission_05_2keV']  # erg * cm**3 * s*-1\n",
    "                    n_h = Gas_density * (0.76/1.6726e-24) * nh_conv  # cm**-3\n",
    "                    n_e = Gas_ea * n_h # cm**-3\n",
    "                    Vol = Gas_mass/Gas_density *(3.086*10**21)**3 # cm**3\n",
    "                    Xray_lum =  Xray_05 * n_e * n_h * Vol # erg/s\n",
    "                    \n",
    "                    result[sim][halo_key]['Lx_05_2keV'] = Xray_lum # erg*s\n",
    "                    result[sim][halo_key]['radius'] = Gas_radius # pkpc\n",
    "                    result[sim][halo_key]['R200c'] = R200c # pkpc\n",
    "                    result[sim][halo_key]['R500c'] = R500c # pkpc\n",
    "                    \n",
    "                   \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7daeaedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/xray_lum.pickle', 'wb') as file:\n",
    "#    pickle.dump(Xray_lumdict(basepaths, basepaths2), file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d68b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xray_line_dict(sim_dict, sim_dict2):\n",
    "    '''\n",
    "    takes 2 dicts as input, sim_dict is { sim: [basepath,snapshot] } where basepath locates the Xray data\n",
    "    sim_dict2 is the same where basepath2 locates the output data (regular path)\n",
    "    returns a nested dict { sim: { haloID: { Xray_emission: values(for each gas cell) } } }\n",
    "    '''\n",
    "    \n",
    "    # initialise output dict\n",
    "    result = {}\n",
    "    \n",
    "    #loop for each sim\n",
    "    for sim2, basepath2 in sim_dict2.items():\n",
    "        \n",
    "        # get the ids of relevant mass halos\n",
    "        group_masses, haloIDs = mass_mask(basepath2[0], basepath2[1]) \n",
    "        \n",
    "        \n",
    "        #loop for each sim\n",
    "        for sim, basepath in sim_dict.items() :\n",
    "            if sim == sim2:\n",
    "                # start a new dict to save values of each sim\n",
    "                result[sim] = {}\n",
    "\n",
    "\n",
    "                #loop over the halo ids\n",
    "                for index, haloID in enumerate(haloIDs):\n",
    "\n",
    "                    halo_key = f'{haloID}'\n",
    "                    result[sim][halo_key] = {}\n",
    "\n",
    "                    Xray_em = loadHalo(basepath[0], basepath[1], haloID , 0) # erg*cm³/s\n",
    "\n",
    "                    result[sim][halo_key]['CVI_Line'] = Xray_em['CVI_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['CV_Line'] = Xray_em['CV_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['FeXVII_Line'] = Xray_em['FeXVII_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['NVII_Line'] = Xray_em['NVII_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['NVI_Line'] = Xray_em['NVI_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['NeX_Line'] = Xray_em['NeX_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['OVIII_Line'] = Xray_em['OVIII_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['OVIIf_Line'] = Xray_em['OVIIf_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['OVIIr_Line'] = Xray_em['OVIIr_Line'] # erg*cm³/s\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "761c387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/xray_line_em.pickle', 'wb') as file:\n",
    "#    pickle.dump(Xray_line_dict(basepaths,basepaths2), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8a72457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xray_line_lumdict(sim_dict, sim_dict2):\n",
    "    '''\n",
    "    takes 2 dicts as input, sim_dict is { sim: [basepath,snapshot] } where basepath locates the Xray data\n",
    "    sim_dict2 is the same where basepath2 locates the output data (regular path)\n",
    "    returns a nested dict { sim: { haloID: { field : value array } } }\n",
    "    '''\n",
    "    \n",
    "    # initialise output dict\n",
    "    result = {}\n",
    "    \n",
    "    #loop for each sim\n",
    "    for sim2, basepath2 in sim_dict2.items():\n",
    "        \n",
    "\n",
    "        # load header\n",
    "        header = il.groupcat.loadHeader(basepath2[0] , basepath2[1] )\n",
    "        h = header['HubbleParam']\n",
    "        a = header['Time']\n",
    "        BoxSize = header['BoxSize'] *a/h # pkpc\n",
    "        \n",
    "        \n",
    "        # get the ids of relevant mass halos\n",
    "        group_masses, haloIDs = mass_mask(basepath2[0], basepath2[1]) \n",
    "        \n",
    "        \n",
    "        # load all halos\n",
    "        Halos = il.groupcat.loadHalos(basepath2[0], basepath2[1], fields=['GroupPos', 'Group_R_Crit500', 'Group_R_Crit200'])\n",
    "        \n",
    "        \n",
    "        #loop for each sim\n",
    "        for sim, basepath in sim_dict.items() :\n",
    "            if sim == sim2:\n",
    "                \n",
    "                # start a new dict to save values of each sim\n",
    "                result[sim] = {}\n",
    "                \n",
    "                \n",
    "                #loop over the halo ids\n",
    "                for index, haloID in enumerate(haloIDs):\n",
    "\n",
    "                    halo_key = f'{haloID}'\n",
    "                    result[sim][halo_key] = {}\n",
    "                    \n",
    "                    \n",
    "                    # define halo data\n",
    "                    halo_pos = Halos['GroupPos'][haloID] *a/h  # pkpc\n",
    "                    R200c = Halos['Group_R_Crit200'][haloID] *a/h # pkpc\n",
    "                    R500c = Halos['Group_R_Crit500'][haloID] *a/h # pkpc\n",
    "\n",
    "                             \n",
    "                    # load gas data\n",
    "                    Gas = il.snapshot.loadHalo(basepath2[0] , basepath2[1] , haloID, 0)            \n",
    "                    Gas_mass = Gas['Masses'] *10**10/h  # Msun\n",
    "                    Gas_ea = Gas['ElectronAbundance'] # unitless\n",
    "                    Gas_density = Gas['Density'] *(10**10/h)/(a/h)**3 # Msun/pkpc³\n",
    "                    Gas_coords = Gas['Coordinates'] *a/h  # pkpc\n",
    "                    Centred_gas = shift(Gas_coords, halo_pos, BoxSize)\n",
    "                    Gas_radius = np.linalg.norm(Centred_gas, axis =1)\n",
    "                    \n",
    "                    \n",
    "                    # load xray data\n",
    "                    Lines = ['OVIIr_Line', 'OVIIf_Line', 'OVIII_Line', 'NeX_Line', 'NVII_Line', 'FeXVII_Line', 'CVI_Line', 'CV_Line', 'NVI_Line']\n",
    "                    Xray_line_em = loadHalo(basepath[0], basepath[1], haloID, 0, fields = Lines) # erg*cm³/s\n",
    "                    \n",
    "                    \n",
    "                    # calc Lx\n",
    "                    Xray_lum = {}\n",
    "                    nh_conv = 6.768 *10**-32\n",
    "                    n_h = Gas_density * (0.76/1.6726e-24) * nh_conv  # cm**-3\n",
    "                    n_e = Gas_ea * n_h # cm**-3\n",
    "                    Vol = Gas_mass/Gas_density *(3.086*10**21)**3 # cm**3\n",
    "                    \n",
    "                    for line in Lines:\n",
    "                        Xray_lum[line] =  Xray_line_em[line] * n_e * n_h * Vol # erg/s\n",
    "                    \n",
    "                    \n",
    "                    result[sim][halo_key]['CVI_Line'] = Xray_lum['CVI_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['CV_Line'] = Xray_lum['CV_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['FeXVII_Line'] = Xray_lum['FeXVII_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['NVII_Line'] = Xray_lum['NVII_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['NVI_Line'] = Xray_lum['NVI_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['NeX_Line'] = Xray_lum['NeX_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['OVIII_Line'] = Xray_lum['OVIII_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['OVIIf_Line'] = Xray_lum['OVIIf_Line'] # erg*cm³/s\n",
    "                    result[sim][halo_key]['OVIIr_Line'] = Xray_lum['OVIIr_Line'] # erg*cm³/s\n",
    "\n",
    "                    result[sim][halo_key]['radius'] = Gas_radius # pkpc\n",
    "                    result[sim][halo_key]['R200c'] = R200c # pkpc\n",
    "                    result[sim][halo_key]['R500c'] = R500c # pkpc\n",
    "                    \n",
    "                   \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "671e314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/xray_line_lum.pickle', 'wb') as file:\n",
    "#    pickle.dump(Xray_line_lumdict(basepaths, basepaths2), file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa540e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
